import asyncio
import json
import re
import time
from typing import Any, AsyncGenerator, Optional, Callable

# [REFAC-01] Structural Boundary Pattern
# Detects the inception of an XML tool block based on structure:
# 1. Anchor: Start of string (^) or Newline (\n)
# 2. Whitespace: Any indentation (\s*)
# 3. Optional Fence: ``` followed by any language tag (alphanumeric) or empty, plus whitespace
# 4. Trigger: XML Tag Start (<tagname) followed by Space (for attributes) or > (immediate close)
TOOL_STRUCTURE_PATTERN = re.compile(r'(?:^|\n)\s*(?:```[a-zA-Z0-9]*\s*)?<[a-zA-Z0-9_\-]+(?:\s|>)')

async def use_stream_response(req_id: str, timeout: float = 5.0, page=None, check_client_disconnected: Optional[Callable] = None, stream_start_time: float = 0.0) -> AsyncGenerator[Any, None]:
    """Enhanced stream response handler with UI-based generation active checks.
    
    Args:
        req_id: Request identifier for logging
        timeout: TTFB timeout in seconds
        page: Playwright page instance for UI state checks
        check_client_disconnected: Optional callback to check if client disconnected
        stream_start_time: Timestamp when this specific stream request was initiated. Used to filter out stale queue data.
    """
    from server import STREAM_QUEUE, logger
    from models import ClientDisconnectedError, QuotaExceededError
    from config.global_state import GlobalState
    from config import (
        SCROLL_CONTAINER_SELECTOR,
        CHAT_SESSION_CONTENT_SELECTOR,
        LAST_CHAT_TURN_SELECTOR,
    )
    import queue

    if STREAM_QUEUE is None:
        logger.warning(f"[{req_id}] STREAM_QUEUE is None, æ— æ³•ä½¿ç”¨æµå“åº”")
        return
        
    # å¼•å…¥ PageController ç”¨äº DOM å…œåº•
    from browser_utils.page_controller import PageController

    if stream_start_time == 0.0:
        stream_start_time = time.time() - 10.0 # Fallback: 10s buffer if not provided

    logger.info(f"[{req_id}] å¼€å§‹ä½¿ç”¨æµå“åº” (TTFB Timeout: {timeout:.2f}s, Start Time: {stream_start_time})")

    accumulated_body = ""
    accumulated_reason_len = 0
    total_reason_processed = 0
    total_body_processed = 0
    boundary_transitions = 0
    boundary_buffer = ""  # [REFAC-03] Sliding window for boundary detection
    
    # [REFAC-04] Internal Accumulators for robustness
    # We maintain full state here to ensure downstream consumers (like response_generators)
    # receive the Cumulative data they expect, regardless of whether upstream sends Deltas or Cumulative.
    acc_reason_state = ""
    acc_body_state = ""
    
    # [FIX-11] Flag to track if we have forcefully switched to body mode
    force_body_mode = False
    
    # Track where the split happened in the accumulated reason stream
    split_index = -1

    # Enhanced timeout settings for thinking models
    empty_count = 0
    max_empty_retries = 900  # Increased to 90 seconds (900 * 0.1s)
    initial_wait_limit = int(timeout * 10)
    data_received = False
    has_content = False
    received_items_count = 0
    stale_done_ignored = False
    last_ui_check_time = 0
    ui_check_interval = 30  # Check UI state every 30 empty reads (3 seconds)
    
    # [LOGIC-FIX] Last Packet Watchdog for silence detection
    last_packet_time = time.time()
    silence_detection_threshold = 5.0  # 5 seconds of silence triggers completion
    min_items_before_silence_check = 10  # Only check silence after receiving some data
    
    # UI-based generation check helper
    async def check_ui_generation_active():
        """Check if the AI is still generating based on UI state."""
        if not page:
            return False
            
        try:
            # Check for "Stop generating" button (indicates active generation)
            stop_button = page.locator('button[aria-label="Stop generating"]')
            if await stop_button.is_visible(timeout=1000):
                return True
                
            # Check if submit button is disabled (generation in progress)
            submit_button = page.locator('button[aria-label="Run"].run-button, ms-run-button button[type="submit"].run-button')
            if await submit_button.count() > 0:
                is_disabled = await submit_button.first.is_disabled(timeout=1000)
                if is_disabled:
                    return True
                    
            return False
        except Exception as e:
            # [FIX-ZOMBIE] If target closed, definitely not generating
            if "Target closed" in str(e) or "Connection closed" in str(e):
                return False
            # If UI check fails, assume generation is not active
            return False

    try:
        while True:
            # [FIX-SCROLL] Active Viewport Tracking (Auto-Scroll)
            # Force the viewport to the bottom to prevent DOM virtualization from unloading elements
            if page:
                try:
                    await page.evaluate("""([scrollSel, contentSel, lastTurnSel]) => {
                        // 1. Target the specific AI Studio scroll container (Primary)
                        const scrollContainer = document.querySelector(scrollSel);
                        if (scrollContainer) {
                            scrollContainer.scrollTop = scrollContainer.scrollHeight;
                        }

                        // 2. Target the specific chat turn container (Backup)
                        const sessionContent = document.querySelector(contentSel);
                        if (sessionContent) {
                             // Some versions might scroll this wrapper instead
                             sessionContent.scrollTop = sessionContent.scrollHeight;
                        }
                        
                        // 3. Force the absolute last turn into view (Crucial for Virtual Scroll)
                        // This tells the virtualizer "I am looking at the bottom, please render these elements"
                        const lastTurn = document.querySelector(lastTurnSel);
                        if (lastTurn) {
                            lastTurn.scrollIntoView({behavior: "instant", block: "end"});
                        }
                        
                        // 4. Generic Window scroll (Safety net)
                        window.scrollTo(0, document.body.scrollHeight);
                    }""", [SCROLL_CONTAINER_SELECTOR, CHAT_SESSION_CONTENT_SELECTOR, LAST_CHAT_TURN_SELECTOR])
                except Exception:
                    pass

            # [ROBUST-02] Check for Quota Exceeded
            if GlobalState.IS_QUOTA_EXCEEDED:
                logger.warning(f"[{req_id}] â›” Quota detected during wait loop. Aborting request immediately.")
                raise QuotaExceededError("Global Quota Limit Reached during stream wait.")

            # [FIX-SHUTDOWN] Check for Global Shutdown
            if GlobalState.IS_SHUTTING_DOWN.is_set():
                logger.warning(f"[{req_id}] ğŸ›‘ Global Shutdown detected during wait loop. Aborting stream.")
                yield {"done": True, "reason": "global_shutdown", "body": "", "function": []}
                return

            try:
                data = STREAM_QUEUE.get_nowait()
                # [SYNC-FIX] CRITICAL: DONE signal forces immediate exit, ignoring all other conditions
                if data is None:
                    logger.info(f"[{req_id}] ğŸ”´ CRITICAL: Received stream termination signal (None). Forcing immediate exit.")
                    break
                empty_count = 0
                data_received = True
                received_items_count += 1
                # [LOGIC-FIX] Update last packet time for silence detection
                last_packet_time = time.time()
                logger.debug(f"[{req_id}] æ¥æ”¶åˆ°æµæ•°æ®[#{received_items_count}]: {type(data)} - {str(data)[:200]}...")

                # [FIX-TIMESTAMP] Handle wrapped data with timestamp
                actual_data = data
                data_ts = 0.0
                
                if isinstance(data, str):
                    try:
                        parsed_wrapper = json.loads(data)
                        # Check if it's the new wrapped format: {"ts": float, "data": ...}
                        if isinstance(parsed_wrapper, dict) and "ts" in parsed_wrapper and "data" in parsed_wrapper:
                            data_ts = parsed_wrapper["ts"]
                            # Filter out stale data from previous requests
                            if data_ts < stream_start_time:
                                logger.warning(f"[{req_id}] ğŸ—‘ï¸ Ignoring stale stream data (Timestamp: {data_ts} < Start: {stream_start_time})")
                                continue
                            actual_data = parsed_wrapper["data"]
                        else:
                            # Legacy format (direct data) - accept but warn? Or just accept.
                            actual_data = parsed_wrapper
                    except json.JSONDecodeError:
                        pass # Handle as raw string below if needed

                # Process the actual data payload
                if isinstance(actual_data, dict):
                    # It was already a dict (from wrapper or raw dict in queue)
                    parsed_data = actual_data
                    
                    # [REFAC-05] Robust Accumulation & Switching Logic (Dict)
                    p_reason = parsed_data.get("reason", "")
                    p_body = parsed_data.get("body", "")
                    
                    # 1. Update Accumulators
                    if p_reason and acc_reason_state and p_reason.startswith(acc_reason_state):
                            acc_reason_state = p_reason
                            new_reason_delta = p_reason[len(acc_reason_state):]
                    else:
                            acc_reason_state += p_reason
                            new_reason_delta = p_reason
                            
                    if p_body and acc_body_state and p_body.startswith(acc_body_state):
                            acc_body_state = p_body
                    else:
                            acc_body_state += p_body

                    # 2. Apply Boundary Logic
                    if force_body_mode:
                        thought_part = acc_reason_state[:split_index]
                        overflow_tool_part = acc_reason_state[split_index:]
                        
                        parsed_data["reason"] = thought_part
                        parsed_data["body"] = acc_body_state + overflow_tool_part
                    else:
                        text_to_check = boundary_buffer + new_reason_delta
                        match = TOOL_STRUCTURE_PATTERN.search(text_to_check)
                        
                        if match:
                            offset = len(acc_reason_state) - len(text_to_check)
                            absolute_split_index = offset + match.start()
                            
                            split_index = absolute_split_index
                            force_body_mode = True
                            boundary_transitions += 1
                            
                            thought_part = acc_reason_state[:split_index]
                            overflow_tool_part = acc_reason_state[split_index:]
                            
                            parsed_data["reason"] = thought_part
                            parsed_data["body"] = acc_body_state + overflow_tool_part
                            logger.info(f"[{req_id}] âœ‚ï¸ Dict Boundary Split Applied.")
                        else:
                            parsed_data["reason"] = acc_reason_state
                            parsed_data["body"] = acc_body_state
                            boundary_buffer = (boundary_buffer + new_reason_delta)[-100:]

                    body = parsed_data.get("body", "")
                    reason = parsed_data.get("reason", "")
                    
                    # Update totals with detailed logging
                    body_increment = len(body)
                    reason_increment = len(reason)
                    accumulated_body += body
                    accumulated_reason_len += len(reason)
                    total_body_processed += body_increment
                    total_reason_processed += reason_increment
                    
                    if body or reason:
                        has_content = True
                    stale_done_ignored = False
                    
                    yield parsed_data
                    
                    # [SYNC-FIX] CRITICAL: Dict DONE signal forces immediate exit, ignoring UI state
                    if parsed_data.get("done") is True:
                        logger.info(f"[{req_id}] ğŸ”´ CRITICAL: Dict DONE received. Body={len(body)}, Reason={len(reason)}. Forcing immediate stream completion.")
                        
                        # [FIX-06] Thinking-to-Answer Handover Protocol (Copied from string branch)
                        if accumulated_reason_len > 0 and len(accumulated_body) == 0:
                             logger.info(f"[{req_id}] âš ï¸ [Dict Path] æ£€æµ‹åˆ° Thinking-Only å“åº”. å¯åŠ¨ DOM Body-Wait åè®®...")
                             try:
                                if page:
                                    pc = PageController(page, logger, req_id)
                                    wait_attempts = 20
                                    dom_body_found = False
                                    for wait_i in range(wait_attempts):
                                        await asyncio.sleep(0.5)
                                        dom_text = await pc.get_body_text_only_from_dom()
                                        if dom_text and len(dom_text.strip()) > 0:
                                            logger.info(f"[{req_id}] âœ… [Dict Path] DOM æ•è·åˆ°æ­£æ–‡: {len(dom_text)} chars")
                                            yield {"body": dom_text, "reason": "", "done": False}
                                            dom_body_found = True
                                            break
                                    if not dom_body_found:
                                        logger.warning(f"[{req_id}] âš ï¸ [Dict Path] DOM ç­‰å¾…è¶…æ—¶ã€‚")
                             except Exception as e:
                                 logger.error(f"[{req_id}] âŒ [Dict Path] DOM Wait Error: {e}")

                        if not has_content and received_items_count == 1 and not stale_done_ignored:
                            logger.warning(f"[{req_id}] âš ï¸ æ”¶åˆ°done=Trueä½†æ²¡æœ‰ä»»ä½•å†…å®¹ï¼Œä¸”è¿™æ˜¯ç¬¬ä¸€ä¸ªæ¥æ”¶çš„é¡¹ç›®ï¼å¯èƒ½æ˜¯é˜Ÿåˆ—æ®‹ç•™çš„æ—§æ•°æ®ï¼Œå°è¯•å¿½ç•¥å¹¶ç»§ç»­ç­‰å¾…...")
                            stale_done_ignored = True
                            continue
                        break
                    else:
                        stale_done_ignored = False
                        
                elif isinstance(actual_data, str):
                    # Fallback for string data that wasn't JSON or wasn't handled above
                    # (This branch is mostly legacy/fallback now as everything comes as dict or wrapped dict)
                    pass

                # Removed the large duplicate 'if isinstance(data, str)' block as we handle it via parsing above
                # and treating result as dict.
                
                continue # Loop back for next item

                # [Legacy Code Block - Kept for reference but unreachable due to 'continue' above and logic refactor]
                # The following block was the original string handling logic.
                # We have integrated it into the unified flow above.
                
                if isinstance(data, str):
                    try:
                        parsed_data = json.loads(data)
                        p_reason = parsed_data.get("reason", "")
                        p_body = parsed_data.get("body", "")
                        
                        # 1. Update Accumulators (Handle Delta vs Cumulative Input)
                        # Detect if input is cumulative (starts with current state) or delta
                        if p_reason and acc_reason_state and p_reason.startswith(acc_reason_state):
                             # Input is cumulative, just update state
                             acc_reason_state = p_reason
                             new_reason_delta = p_reason[len(acc_reason_state):] # effective delta for buffer
                        else:
                             # Input is delta, append to state
                             acc_reason_state += p_reason
                             new_reason_delta = p_reason
                             
                        if p_body and acc_body_state and p_body.startswith(acc_body_state):
                             acc_body_state = p_body
                        else:
                             acc_body_state += p_body

                        # 2. Apply Boundary Logic
                        if force_body_mode:
                            # We have already split.
                            # reason = accumulated thought up to split
                            # body = accumulated body + (accumulated reason - thought)
                            
                            thought_part = acc_reason_state[:split_index]
                            overflow_tool_part = acc_reason_state[split_index:]
                            
                            parsed_data["reason"] = thought_part
                            parsed_data["body"] = acc_body_state + overflow_tool_part
                            
                        else:
                            # Check for boundary in the *new* content (plus context)
                            # We use boundary_buffer (last 100 chars) + new_reason_delta
                            text_to_check = boundary_buffer + new_reason_delta
                            match = TOOL_STRUCTURE_PATTERN.search(text_to_check)
                            
                            if match:
                                # Found the boundary!
                                logger.info(f"[{req_id}] ğŸ” Detected Tool Structure: {match.group(0).strip()!r}")
                                
                                # Calculate absolute split index in acc_reason_state
                                # match.start() is relative to text_to_check
                                # text_to_check start corresponds to (len(acc_reason_state) - len(text_to_check))
                                offset = len(acc_reason_state) - len(text_to_check)
                                absolute_split_index = offset + match.start()
                                
                                split_index = absolute_split_index
                                force_body_mode = True
                                boundary_transitions += 1
                                
                                # Apply split immediately
                                thought_part = acc_reason_state[:split_index]
                                overflow_tool_part = acc_reason_state[split_index:]
                                
                                parsed_data["reason"] = thought_part
                                parsed_data["body"] = acc_body_state + overflow_tool_part
                                
                                logger.info(f"[{req_id}] âœ‚ï¸ Boundary Split Applied. Thought len: {len(thought_part)}")
                            else:
                                # No match, pass through accumulated states as is
                                parsed_data["reason"] = acc_reason_state
                                parsed_data["body"] = acc_body_state
                                
                                # Update sliding window buffer for next check
                                boundary_buffer = (boundary_buffer + new_reason_delta)[-100:]

                        # [SYNC-FIX] CRITICAL: JSON DONE signal forces immediate exit, ignoring UI state
                        if parsed_data.get("done") is True:
                            body = parsed_data.get("body", "")
                            reason = parsed_data.get("reason", "")
                            
                            # Update totals with detailed logging
                            body_increment = len(body)
                            reason_increment = len(reason)
                            accumulated_body += body
                            accumulated_reason_len += len(reason)
                            total_body_processed += body_increment
                            total_reason_processed += reason_increment
                            boundary_transitions += 1 if force_body_mode else 0
                            
                            if body or reason:
                                has_content = True
                            
                            logger.info(f"[{req_id}] ğŸ”´ CRITICAL: JSON DONE received. Body={len(body)}, Reason={len(reason)}. Forcing immediate stream completion.")
                            
                            # [FIX-06] Thinking-to-Answer Handover Protocol
                            # æ£€æµ‹æ˜¯å¦åªè¾“å‡ºäº†æ€è€ƒè¿‡ç¨‹è€Œæ²¡æœ‰æ­£æ–‡ (Thinking > 0, Body == 0)
                            if accumulated_reason_len > 0 and len(accumulated_body) == 0:
                                logger.info(f"[{req_id}] âš ï¸ æ£€æµ‹åˆ° Thinking-Only å“åº” (Total Reason: {accumulated_reason_len}, Body: 0)ã€‚å¯åŠ¨ DOM Body-Wait åè®®...")
                                
                                try:
                                    if page:
                                        pc = PageController(page, logger, req_id)
                                        # å°è¯•ç­‰å¾…æ­£æ–‡å‡ºç°ï¼Œæœ€å¤šç­‰ 10 ç§’ (20 * 0.5s)
                                        wait_attempts = 20
                                        dom_body_found = False
                                        
                                        for wait_i in range(wait_attempts):
                                            await asyncio.sleep(0.5)
                                            # ä½¿ç”¨æ–°æ·»åŠ çš„ get_body_text_only_from_dom æ–¹æ³•
                                            dom_text = await pc.get_body_text_only_from_dom()
                                            
                                            if dom_text and len(dom_text.strip()) > 0:
                                                logger.info(f"[{req_id}] âœ… åœ¨ç¬¬ {wait_i+1} æ¬¡å°è¯•ä¸­é€šè¿‡ DOM æ•è·åˆ°æ­£æ–‡: {len(dom_text)} chars")
                                                
                                                # [Sanity Check] Prevent Duplication
                                                # å¦‚æœ stream å‘é€äº†éƒ¨åˆ†å†…å®¹ï¼ˆè™½ç„¶è¿™é‡Œæ˜¯ body==0 çš„åˆ†æ”¯ï¼Œä½†ä¸ºäº†ä»£ç å¥å£®æ€§ä¿ç•™æ£€æŸ¥é€»è¾‘ï¼‰
                                                final_text_to_yield = dom_text
                                                if len(accumulated_body) > 0:
                                                    if dom_text.startswith(accumulated_body):
                                                        final_text_to_yield = dom_text[len(accumulated_body):]
                                                        logger.info(f"[{req_id}] å»é‡: å‰”é™¤å·²å‘é€çš„ {len(accumulated_body)} å­—ç¬¦")
                                                
                                                if final_text_to_yield:
                                                    # æ„é€ ä¸€ä¸ªæ–°çš„ body chunk
                                                    new_chunk = {
                                                        "body": final_text_to_yield,
                                                        "reason": "",
                                                        "done": False
                                                    }
                                                    yield new_chunk
                                                    accumulated_body += final_text_to_yield
                                                    total_body_processed += len(final_text_to_yield)
                                                    dom_body_found = True
                                                    break
                                        
                                        if not dom_body_found:
                                            logger.warning(f"[{req_id}] âš ï¸ DOM ç­‰å¾…è¶…æ—¶ï¼Œä»æœªè·å–åˆ°æ­£æ–‡ã€‚å°†æ‰§è¡Œ Fallback (å¤åˆ¶æ€è€ƒå†…å®¹æˆ–æç¤ºé”™è¯¯)ã€‚")
                                    else:
                                        logger.warning(f"[{req_id}] âš ï¸ æ— æ³•æ‰§è¡Œ DOM Wait (Page å¯¹è±¡ä¸ºç©º)ã€‚")
                                except Exception as dom_wait_err:
                                    logger.error(f"[{req_id}] âŒ DOM Body-Wait åè®®æ‰§è¡Œå‡ºé”™: {dom_wait_err}")

                            if not has_content and received_items_count == 1 and not stale_done_ignored:
                                logger.warning(f"[{req_id}] âš ï¸ æ”¶åˆ°done=Trueä½†æ²¡æœ‰ä»»ä½•å†…å®¹ï¼Œä¸”è¿™æ˜¯ç¬¬ä¸€ä¸ªæ¥æ”¶çš„é¡¹ç›®ï¼å¯èƒ½æ˜¯é˜Ÿåˆ—æ®‹ç•™çš„æ—§æ•°æ®ï¼Œå°è¯•å¿½ç•¥å¹¶ç»§ç»­ç­‰å¾…...")
                                stale_done_ignored = True
                                continue
                            yield parsed_data
                            break
                        else:
                            body = parsed_data.get("body", "")
                            reason = parsed_data.get("reason", "")
                            
                            # Update totals with detailed logging
                            body_increment = len(body)
                            reason_increment = len(reason)
                            accumulated_body += body
                            accumulated_reason_len += len(reason)
                            total_body_processed += body_increment
                            total_reason_processed += reason_increment
                            
                            if body or reason:
                                has_content = True
                            stale_done_ignored = False
                            
                            # Log significant content updates
                            if body_increment > 0 or reason_increment > 0:
                                logger.debug(f"[{req_id}] ğŸ“ æ•°æ®å¢é‡: Body +{body_increment}, Reason +{reason_increment}, çŠ¶æ€: ForceBody={force_body_mode}")
                            
                            yield parsed_data
                    except json.JSONDecodeError:
                        logger.debug(f"[{req_id}] è¿”å›éJSONå­—ç¬¦ä¸²æ•°æ®")
                        has_content = True
                        stale_done_ignored = False
                        yield data
                else:
                    # Handle Dict data with enhanced boundary logic
                    if isinstance(data, dict):
                        p_reason = data.get("reason", "")
                        p_body = data.get("body", "")
                        
                        # [REFAC-05] Robust Accumulation & Switching Logic (Dict)
                        p_reason = data.get("reason", "")
                        p_body = data.get("body", "")
                        
                        # 1. Update Accumulators
                        if p_reason and acc_reason_state and p_reason.startswith(acc_reason_state):
                             acc_reason_state = p_reason
                             new_reason_delta = p_reason[len(acc_reason_state):]
                        else:
                             acc_reason_state += p_reason
                             new_reason_delta = p_reason
                             
                        if p_body and acc_body_state and p_body.startswith(acc_body_state):
                             acc_body_state = p_body
                        else:
                             acc_body_state += p_body

                        # 2. Apply Boundary Logic
                        if force_body_mode:
                            thought_part = acc_reason_state[:split_index]
                            overflow_tool_part = acc_reason_state[split_index:]
                            
                            data["reason"] = thought_part
                            data["body"] = acc_body_state + overflow_tool_part
                        else:
                            text_to_check = boundary_buffer + new_reason_delta
                            match = TOOL_STRUCTURE_PATTERN.search(text_to_check)
                            
                            if match:
                                offset = len(acc_reason_state) - len(text_to_check)
                                absolute_split_index = offset + match.start()
                                
                                split_index = absolute_split_index
                                force_body_mode = True
                                boundary_transitions += 1
                                
                                thought_part = acc_reason_state[:split_index]
                                overflow_tool_part = acc_reason_state[split_index:]
                                
                                data["reason"] = thought_part
                                data["body"] = acc_body_state + overflow_tool_part
                                logger.info(f"[{req_id}] âœ‚ï¸ Dict Boundary Split Applied.")
                            else:
                                data["reason"] = acc_reason_state
                                data["body"] = acc_body_state
                                boundary_buffer = (boundary_buffer + new_reason_delta)[-100:]

                        body = data.get("body", "")
                        reason = data.get("reason", "")
                        if body or reason:
                            has_content = True
                        
                        yield data
                        
                        # [SYNC-FIX] CRITICAL: Dict DONE signal forces immediate exit, ignoring UI state
                        if data.get("done") is True:
                            logger.info(f"[{req_id}] ğŸ”´ CRITICAL: Dict DONE received. Body={len(body)}, Reason={len(reason)}. Forcing immediate stream completion.")
                            if not has_content and received_items_count == 1 and not stale_done_ignored:
                                logger.warning(f"[{req_id}] âš ï¸ æ”¶åˆ°done=Trueä½†æ²¡æœ‰ä»»ä½•å†…å®¹ï¼Œä¸”è¿™æ˜¯ç¬¬ä¸€ä¸ªæ¥æ”¶çš„é¡¹ç›®ï¼å¯èƒ½æ˜¯é˜Ÿåˆ—æ®‹ç•™çš„æ—§æ•°æ®ï¼Œå°è¯•å¿½ç•¥å¹¶ç»§ç»­ç­‰å¾…...")
                                stale_done_ignored = True
                                continue
                            break
                        else:
                            stale_done_ignored = False
            except (queue.Empty, asyncio.QueueEmpty):
                empty_count += 1

                # [LOGIC-FIX] Silence Detection: Check if stream has been silent for too long
                if (received_items_count >= min_items_before_silence_check and
                    time.time() - last_packet_time > silence_detection_threshold):
                    logger.info(f"[{req_id}] ğŸ”‡ Stream silence detected ({silence_detection_threshold}s). Assuming generation complete.")
                    yield {"done": True, "reason": "silence_detected", "body": "", "function": []}
                    return

                # Check for disconnect during wait
                if check_client_disconnected:
                    try:
                        check_client_disconnected(f"Stream Queue Wait ({req_id})")
                    except ClientDisconnectedError:
                        logger.warning(f"[{req_id}] å®¢æˆ·ç«¯åœ¨æµå¼é˜Ÿåˆ—ç­‰å¾…æœŸé—´æ–­å¼€è¿æ¥ã€‚")
                        raise

                # Fail-Fast TTFB Check
                if received_items_count == 0 and empty_count >= initial_wait_limit:
                    logger.error(f"[{req_id}] Stream has no data after {empty_count * 0.1:.1f} seconds, aborting (TTFB Timeout).")

                    # Trigger Fail-Fast Browser Reload
                    try:
                        from server import page_instance
                        if page_instance:
                            logger.info(f"[{req_id}] Triggering fail-fast browser reload due to TTFB timeout...")
                            await page_instance.reload()
                    except Exception as reload_err:
                        logger.error(f"[{req_id}] Failed to reload page during TTFB timeout: {reload_err}")

                    yield {"done": True, "reason": "ttfb_timeout", "body": "", "function": []}
                    return

                # [CRITICAL-FIX] Network State Priority: Trust data flow over UI state
                if empty_count >= max_empty_retries:
                    # CRITICAL FIX: Remove UI-based timeout extension
                    # Trust Network State over UI State - force exit on timeout
                    is_thinking = await check_ui_generation_active()
                    if is_thinking:
                        logger.warning(f"[{req_id}] ğŸš¨ TIMEOUT REACHED despite active UI! Forcing stream completion.")
                    else:
                        logger.warning(f"[{req_id}] â° Stream timeout reached ({max_empty_retries} attempts). Ending stream.")
                    
                    if not data_received:
                        logger.error(f"[{req_id}] Stream timeout: no data received, likely auxiliary stream failed")
                    yield {"done": True, "reason": "internal_timeout", "body": "", "function": []}
                    return

                # Periodic logging and UI checks
                if empty_count % 50 == 0:
                    elapsed_seconds = empty_count * 0.1
                    logger.info(f"[{req_id}] ç­‰å¾…æµæ•°æ®... ({empty_count}/{max_empty_retries}, å·²æ”¶åˆ°:{received_items_count}é¡¹, è€—æ—¶:{elapsed_seconds:.1f}s)")
                
                # UI-based generation check every 3 seconds
                if empty_count - last_ui_check_time >= ui_check_interval:
                    ui_generation_active = await check_ui_generation_active()
                    last_ui_check_time = empty_count
                    
                    if ui_generation_active:
                        logger.info(f"[{req_id}] UIæ£€æµ‹åˆ°æ¨¡å‹ä»åœ¨ç”Ÿæˆä¸­ï¼Œç»§ç»­ç­‰å¾…... (å·²ç­‰å¾… {empty_count * 0.1:.1f}s)")
                    else:
                        logger.debug(f"[{req_id}] UIæ£€æµ‹åˆ°æ¨¡å‹æœªåœ¨ç”Ÿæˆ (å·²ç­‰å¾… {empty_count * 0.1:.1f}s)")

                await asyncio.sleep(0.1)
                continue
    except Exception as e:
        if isinstance(e, ClientDisconnectedError):
             logger.info(f"[{req_id}] åœæ­¢æµå“åº”: å®¢æˆ·ç«¯å·²æ–­å¼€ã€‚")
             raise e
        logger.error(f"[{req_id}] ä½¿ç”¨æµå“åº”æ—¶å‡ºé”™: {e}")
        raise
    finally:
        logger.info(
            f"[{req_id}] âœ… æµå“åº”ä½¿ç”¨å®Œæˆç»Ÿè®¡:\n"
            f"  ğŸ“Š æ•°æ®æ¥æ”¶: {data_received}, æœ‰å†…å®¹: {has_content}, æ”¶åˆ°é¡¹ç›®æ•°: {received_items_count}\n"
            f"  ğŸ“ å†…å®¹ç»Ÿè®¡: Body={total_body_processed} chars, Reason={total_reason_processed} chars\n"
            f"  ğŸ”„ è¾¹ç•Œè½¬æ¢: {boundary_transitions} æ¬¡, å¼ºåˆ¶Bodyæ¨¡å¼: {force_body_mode}\n"
            f"  â±ï¸ è¶…æ—¶å¤„ç†: å¿½ç•¥ç©ºdone={stale_done_ignored}, åˆå§‹ç­‰å¾…é™åˆ¶={initial_wait_limit}\n"
            f"  ğŸ§¹ å¼€å§‹æ¸…ç†é˜Ÿåˆ—..."
        )
        # Trigger queue cleanup to prevent residual data
        await clear_stream_queue()


async def clear_stream_queue():
    from server import STREAM_QUEUE, logger
    import queue

    if STREAM_QUEUE is None:
        logger.info("æµé˜Ÿåˆ—æœªåˆå§‹åŒ–æˆ–å·²è¢«ç¦ç”¨ï¼Œè·³è¿‡æ¸…ç©ºæ“ä½œã€‚")
        return

    cleared_count = 0
    while True:
        try:
            data_chunk = await asyncio.to_thread(STREAM_QUEUE.get_nowait)
            cleared_count += 1
            if cleared_count <= 3:
                logger.debug(f"æ¸…ç©ºæµå¼é˜Ÿåˆ—é¡¹ #{cleared_count}: {type(data_chunk)} - {str(data_chunk)[:100]}...")
        except queue.Empty:
            logger.info(f"æµå¼é˜Ÿåˆ—å·²æ¸…ç©º (æ•è·åˆ° queue.Empty)ã€‚æ¸…ç©ºé¡¹æ•°: {cleared_count}")
            break
        except Exception as e:
            logger.error(f"æ¸…ç©ºæµå¼é˜Ÿåˆ—æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯ (å·²æ¸…ç©º{cleared_count}é¡¹): {e}", exc_info=True)
            break
    
    if cleared_count > 0:
        logger.warning(f"âš ï¸ æµå¼é˜Ÿåˆ—ç¼“å­˜æ¸…ç©ºå®Œæ¯•ï¼Œå…±æ¸…ç†äº† {cleared_count} ä¸ªæ®‹ç•™é¡¹ç›®ï¼")
    else:
        logger.info("æµå¼é˜Ÿåˆ—ç¼“å­˜æ¸…ç©ºå®Œæ¯•ï¼ˆé˜Ÿåˆ—ä¸ºç©ºï¼‰ã€‚")